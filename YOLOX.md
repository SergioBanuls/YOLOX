# YOLOX - Entrenamiento y Exportaci√≥n de Modelos

Este proyecto se encarga de **entrenar un modelo YOLOX personalizado** para detectar **caras** (`face`) y **documentos** (`doc_quad`) y **exportarlo al formato ONNX** para su uso en aplicaciones web.

## üìã Descripci√≥n general

El proyecto YOLOX permite:

-   Entrenar un modelo de detecci√≥n personalizado usando el framework YOLOX
-   Exportar el modelo entrenado al formato ONNX
-   Validar y comparar la precisi√≥n entre el modelo PyTorch original y la versi√≥n ONNX exportada
-   Generar modelos optimizados para detecci√≥n en tiempo real

## ÔøΩÔ∏è Instalaci√≥n y Preparaci√≥n del Entorno

### Prerequisitos

-   **Anaconda** instalado en tu sistema
-   **GPU compatible con CUDA** (recomendado para entrenamiento)
-   **Windows 10/11** con soporte para GPU

### 1. Crear entorno conda

Abre **Anaconda Prompt** y ejecuta los siguientes comandos:

```bash
# Crear un nuevo entorno con Python 3.8
conda create -n yolox python=3.8 -y

# Activar el entorno
conda activate yolox
```

### 2. Instalar PyTorch con soporte CUDA

```bash
# Para GPU con CUDA 11.8 (verificar tu versi√≥n de CUDA)
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y

# Si no tienes GPU, usa la versi√≥n CPU:
# conda install pytorch torchvision torchaudio cpuonly -c pytorch -y
```

### 3. Instalar dependencias del proyecto

Navega al directorio del proyecto YOLOX y ejecuta:

```bash
# Navegar al directorio del proyecto
cd ruta\a\tu\proyecto\YOLOX

# Instalar YOLOX en modo desarrollo
pip install -v -e .

# Instalar dependencias adicionales
pip install cython
pip install pycocotools
pip install tensorboard
pip install onnx
pip install onnxruntime
```

### 4. Verificar instalaci√≥n

Verifica que todo est√© instalado correctamente:

```bash
# Verificar PyTorch y CUDA
python -c "import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}' if torch.cuda.is_available() else 'CPU only')"

# Verificar YOLOX
python -c "import yolox; print('YOLOX instalado correctamente')"
```

### 5. Descargar modelo preentrenado

Descarga el modelo base YOLOX-S:

```bash
# Crear directorio para modelos si no existe
mkdir -p models

# Descargar modelo YOLOX-S preentrenado
wget https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_s.pth
```

**Nota:** Si `wget` no est√° disponible en Windows, puedes descargar manualmente desde [GitHub Releases](https://github.com/Megvii-BaseDetection/YOLOX/releases) y colocar `yolox_s.pth` en la ra√≠z del proyecto.

### 6. Configuraci√≥n del archivo de experimento

Aseg√∫rate de que tienes el archivo de configuraci√≥n personalizado:

```bash
# Verificar que existe el archivo de configuraci√≥n
dir exps\example\custom\yolox_doc_face.py
```

Si no existe, cr√©alo bas√°ndote en los archivos de ejemplo en `exps/example/yolox_voc/`.

### ‚ö†Ô∏è Notas importantes

-   **Siempre activa el entorno conda** antes de trabajar: `conda activate yolox`
-   **Verifica tu versi√≥n de CUDA** con `nvidia-smi` antes de instalar PyTorch
-   **Para entrenamientos largos**, considera usar `screen` o `tmux` para mantener la sesi√≥n activa
-   **El entrenamiento con CPU es extremadamente lento**, se recomienda encarecidamente usar GPU

## ÔøΩüîß Scripts principales

### `compare_models.py`

Script para **validar y comparar** el rendimiento entre:

-   Modelo PyTorch original (`.pth`)
-   Modelo ONNX exportado (`.onnx`)

√ötil para verificar que la exportaci√≥n se realiz√≥ correctamente y que ambos modelos producen resultados similares.

### `export_correct_ONNX.py`

Script principal para **exportar el modelo entrenado al formato ONNX**. Este script:

-   Carga el checkpoint del modelo entrenado
-   Configura correctamente las clases y par√°metros
-   Exporta el modelo a formato ONNX optimizado para inferencia web
-   Genera el archivo `yolox_doc_face_fixed.onnx`

## üìÅ Preparaci√≥n del Dataset

**IMPORTANTE:** Antes de ejecutar cualquier entrenamiento, debes preparar correctamente tu dataset siguiendo estos pasos:

### 1. Estructura de directorios requerida

```
datasets/
‚îî‚îÄ‚îÄ VOCdevkit/
    ‚îú‚îÄ‚îÄ annotations_cache/  # Cach√© generado autom√°ticamente
    ‚îî‚îÄ‚îÄ VOC2020/
        ‚îú‚îÄ‚îÄ Annotations/    # Archivos .xml con anotaciones
        ‚îú‚îÄ‚îÄ JPEGImages/     # Im√°genes del dataset
        ‚îî‚îÄ‚îÄ ImageSets/
            ‚îî‚îÄ‚îÄ Main/
                ‚îú‚îÄ‚îÄ train.txt  # Lista de archivos de entrenamiento
                ‚îî‚îÄ‚îÄ val.txt    # Lista de archivos de validaci√≥n
```

### 2. üì∏ Preparaci√≥n de las im√°genes

-   **Coloca todas las im√°genes en la carpeta `JPEGImages/`**
-   Las im√°genes deben estar en formato JPEG (extensi√≥n `.jpg`)
-   **Cada imagen debe tener un archivo XML de anotaci√≥n correspondiente con el mismo nombre**
    -   Ejemplo: `imagen001.jpg` ‚Üí `imagen001.xml`

### 3. üìù Formato de anotaciones XML

Cada archivo XML en la carpeta `Annotations/` debe seguir el formato VOC:

```xml
<annotation>
  <filename>imagen001.jpg</filename>
  <size>
    <width>2268</width>
    <height>4032</height>
    <depth>3</depth>
  </size>
  <object>
    <name>face</name>
    <bndbox>
      <xmin>100</xmin>
      <ymin>200</ymin>
      <xmax>300</xmax>
      <ymax>400</ymax>
    </bndbox>
  </object>
  <object>
    <name>doc_quad</name>
    <bndbox>
      <xmin>500</xmin>
      <ymin>600</ymin>
      <xmax>800</xmax>
      <ymax>900</ymax>
    </bndbox>
  </object>
  <!-- Agregar m√°s objetos seg√∫n sea necesario -->
</annotation>
```

### 4. Archivos de divisi√≥n del dataset

Genera dos archivos de texto en `ImageSets/Main/`:

#### `train.txt`

Contiene la lista de nombres de im√°genes (sin extensi√≥n .xml) para entrenamiento:

```
imagen001
imagen002
imagen003
...
```

#### `val.txt`

Contiene la lista de nombres de im√°genes (sin extensi√≥n .xml) para validaci√≥n:

```
imagen004
imagen005
imagen006
...
```

**Notas importantes:**

-   **Cada l√≠nea debe contener solo el nombre del archivo sin extensi√≥n** (sin .jpg ni .xml)
-   T√≠picamente se usa una divisi√≥n 80/20 (80% entrenamiento, 20% validaci√≥n)
-   Los nombres en estos archivos deben corresponder a im√°genes y archivos XML existentes
-   Cada imagen listada debe tener tanto un archivo `.jpg` en `JPEGImages/` como un archivo `.xml` en `Annotations/`

### 5. ‚úÖ Lista de verificaci√≥n

Antes del entrenamiento, aseg√∫rate de que:

-   [ ] Todas las im√°genes est√°n en la carpeta `JPEGImages/`
-   [ ] Todas las anotaciones XML est√°n en la carpeta `Annotations/`
-   [ ] Cada imagen tiene un archivo XML correspondiente con el mismo nombre
-   [ ] Los archivos `train.txt` y `val.txt` est√°n correctamente generados
-   [ ] Los archivos XML siguen el formato VOC correcto
-   [ ] No faltan archivos referenciados en train.txt o val.txt

### ‚ö†Ô∏è Importante sobre el cach√©

-   Si agregas **nuevas im√°genes** al dataset, **DEBES BORRAR** el directorio `annotations_cache/` que se encuentra dentro de `VOCdevkit/`
-   Este cach√© puede causar problemas si no se actualiza despu√©s de modificar el dataset

## üöÄ C√≥mo usar

### 0. Activar entorno conda

**IMPORTANTE:** Siempre activa el entorno antes de ejecutar cualquier comando:

```bash
conda activate yolox
```

### 1. Preparar el dataset

Aseg√∫rate de tener la estructura de directorios correcta con:

-   Im√°genes en `VOCdevkit/VOC2020/JPEGImages/`
-   Anotaciones XML en `VOCdevkit/VOC2020/Annotations/`
-   Archivos de divisi√≥n en `VOCdevkit/VOC2020/ImageSets/Main/`

### 2. Ejecutar el entrenamiento

```bash
python tools/train.py -f exps/example/custom/yolox_doc_face.py -d 1 -b 8 --fp16 -o -c yolox_s.pth
```

### 3. Exportar a ONNX

```bash
python export_correct_ONNX.py
```

### 4. Validar el modelo exportado

```bash
python compare_models.py
```

## üîß Soluci√≥n de Problemas Comunes

### Error de CUDA out of memory

```bash
# Reducir batch size en el comando de entrenamiento
python tools/train.py -f exps/example/custom/yolox_doc_face.py -d 1 -b 4 --fp16 -o -c yolox_s.pth
```

### Error de dependencias faltantes

```bash
# Reinstalar dependencias principales
pip install --upgrade setuptools wheel
pip install cython numpy
pip install -v -e .
```

### Error "module 'yolox' not found"

```bash
# Verificar que est√°s en el entorno correcto
conda activate yolox

# Reinstalar YOLOX
pip uninstall yolox -y
pip install -v -e .
```

## üì§ Salida del modelo

El modelo exportado se guarda como:

-   **Archivo:** `yolox_doc_face_fixed.onnx`
-   **Ubicaci√≥n:** Ra√≠z del proyecto YOLOX
-   **Uso:** Debe copiarse a `cam-detector/public/` para usar en la aplicaci√≥n web

## üîç Verificaci√≥n de resultados

-   **Carpeta de salida:** `demo_output/` - Contiene im√°genes de prueba procesadas
-   **Logs de entrenamiento:** `YOLOX_outputs/` - Contiene checkpoints y m√©tricas del entrenamiento

## üéØ Clases detectadas

El modelo est√° entrenado para detectar:

1. **`face`** - Caras humanas
2. **`doc_quad`** - Documentos (cuadril√°teros)

## üîó Integraci√≥n con CAMDetector

Una vez exportado el modelo ONNX:

1. Copia `yolox_doc_face_fixed.onnx` a `cam-detector/public/`
2. Ren√≥mbralo a `yolox_doc_face_decoded.onnx` (seg√∫n configuraci√≥n de CAMDetector)
3. Ejecuta la aplicaci√≥n web CAMDetector para pruebas en tiempo real

---

**Siguiente paso:** Consulta [CAMDetector.md](./CAMDetector.md) para usar el modelo exportado en la aplicaci√≥n web.
